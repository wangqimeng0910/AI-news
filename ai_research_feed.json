{
  "generated_at": "2025-12-20T02:42:33.065141+00:00",
  "count": 25,
  "items": [
    {
      "source_id": "openai_news",
      "source_name": "OpenAI News",
      "category": "company",
      "title": "Evaluating chain-of-thought monitorability",
      "link": "https://openai.com/index/evaluating-chain-of-thought-monitorability",
      "published": "2025-12-18T12:00:00+00:00",
      "summary": "OpenAI introduces a new framework and evaluation suite for chain-of-thought monitorability, covering 13 evaluations across 24 environments. Our findings show that monitoring a model’s internal reasoning is far more effective than monitoring outputs alone, offering a promising path toward scalable control as AI systems grow more capable."
    },
    {
      "source_id": "openai_news",
      "source_name": "OpenAI News",
      "category": "company",
      "title": "AI literacy resources for teens and parents",
      "link": "https://openai.com/index/ai-literacy-resources-for-teens-and-parents",
      "published": "2025-12-18T11:00:00+00:00",
      "summary": "OpenAI shares new AI literacy resources to help teens and parents use ChatGPT thoughtfully, safely, and with confidence. The guides include expert-vetted tips for responsible use, critical thinking, healthy boundaries, and supporting teens through emotional or sensitive topics."
    },
    {
      "source_id": "openai_news",
      "source_name": "OpenAI News",
      "category": "company",
      "title": "Deepening our collaboration with the U.S. Department of Energy",
      "link": "https://openai.com/index/us-department-of-energy-collaboration",
      "published": "2025-12-18T11:00:00+00:00",
      "summary": "OpenAI and the U.S. Department of Energy have signed a memorandum of understanding to deepen collaboration on AI and advanced computing in support of scientific discovery. The agreement builds on ongoing work with national laboratories and helps establish a framework for applying AI to high-impact research across the DOE ecosystem."
    },
    {
      "source_id": "openai_news",
      "source_name": "OpenAI News",
      "category": "company",
      "title": "Updating our Model Spec with teen protections",
      "link": "https://openai.com/index/updating-model-spec-with-teen-protections",
      "published": "2025-12-18T11:00:00+00:00",
      "summary": "OpenAI is updating its Model Spec with new Under-18 Principles that define how ChatGPT should support teens with safe, age-appropriate guidance grounded in developmental science. The update strengthens guardrails, clarifies expected model behavior in higher-risk situations, and builds on our broader work to improve teen safety across ChatGPT."
    },
    {
      "source_id": "openai_news",
      "source_name": "OpenAI News",
      "category": "company",
      "title": "Introducing GPT-5.2-Codex",
      "link": "https://openai.com/index/introducing-gpt-5-2-codex",
      "published": "2025-12-18T00:00:00+00:00",
      "summary": "GPT-5.2-Codex is OpenAI’s most advanced coding model, offering long-horizon reasoning, large-scale code transformations, and enhanced cybersecurity capabilities."
    },
    {
      "source_id": "deepmind_news",
      "source_name": "Google DeepMind",
      "category": "company",
      "title": "Watch a podcast discussion about Gemini 3 and the future of Search.",
      "link": "https://blog.google/technology/ai/release-notes-podcast-search/",
      "published": "2025-12-18T00:00:00+00:00",
      "summary": "Learn how Gemini 3 powers Google Search with Generative UI, Nano Banana, and interactive graphics."
    },
    {
      "source_id": "deepmind_news",
      "source_name": "Google DeepMind",
      "category": "company",
      "title": "Gemini 3 Flash: frontier intelligence built for speed",
      "link": "https://blog.google/products/gemini/gemini-3-flash/",
      "published": "2025-12-17T16:00:00+00:00",
      "summary": "Gemini 3 Flash text"
    },
    {
      "source_id": "deepmind_news",
      "source_name": "Google DeepMind",
      "category": "company",
      "title": "The latest AI news we announced in November",
      "link": "https://blog.google/technology/ai/google-ai-updates-november-2025/",
      "published": "2025-12-05T19:45:00+00:00",
      "summary": "mp4 showing a carousel of images with text like \"Gemini 3\" \"Nano Banana Pro\" and \"Help me plan a trip\""
    },
    {
      "source_id": "deepmind_news",
      "source_name": "Google DeepMind",
      "category": "company",
      "title": "Watch ‘The Thinking Game,’ a documentary about Google DeepMind, for free on YouTube.",
      "link": "https://blog.google/technology/google-deepmind/the-thinking-game/",
      "published": "2025-11-25T16:00:00+00:00",
      "summary": "We’re bringing “The Thinking Game\" to the Google DeepMind YouTube channel."
    },
    {
      "source_id": "deepmind_news",
      "source_name": "Google DeepMind",
      "category": "company",
      "title": "How we’re bringing AI image verification to the Gemini app",
      "link": "https://blog.google/technology/ai/ai-image-verification-gemini-app/",
      "published": "2025-11-20T15:00:00+00:00",
      "summary": "Golden retriever catching frisbee over water. UI overlay shows Google AI watermark detected."
    },
    {
      "source_id": "arxiv_cs_lg",
      "source_name": "arXiv cs.LG (Machine Learning)",
      "category": "arxiv",
      "title": "DiscoverDCP: A Data-Driven Approach for Construction of Disciplined Convex Programs via Symbolic Regression",
      "link": "https://arxiv.org/abs/2512.15721",
      "published": "2025-12-19T05:00:00+00:00",
      "summary": "arXiv:2512.15721v1 Announce Type: new Abstract: We propose DiscoverDCP, a data-driven framework that integrates symbolic regression with the rule sets of Disciplined Convex Programming (DCP) to perform system identification. By enforcing that all discovered candidate model expressions adhere to DCP composition rules, we ensure that the output expressions are globally convex by construction, circum..."
    },
    {
      "source_id": "arxiv_cs_lg",
      "source_name": "arXiv cs.LG (Machine Learning)",
      "category": "arxiv",
      "title": "Hybrid Quantum-Classical Ensemble Learning for S\\&P 500 Directional Prediction",
      "link": "https://arxiv.org/abs/2512.15738",
      "published": "2025-12-19T05:00:00+00:00",
      "summary": "arXiv:2512.15738v1 Announce Type: new Abstract: Financial market prediction is a challenging application of machine learning, where even small improvements in directional accuracy can yield substantial value. Most models struggle to exceed 55--57\\% accuracy due to high noise, non-stationarity, and market efficiency. We introduce a hybrid ensemble framework combining quantum sentiment analysis, Dec..."
    },
    {
      "source_id": "arxiv_cs_lg",
      "source_name": "arXiv cs.LG (Machine Learning)",
      "category": "arxiv",
      "title": "SHARe-KAN: Holographic Vector Quantization for Memory-Bound Inference",
      "link": "https://arxiv.org/abs/2512.15742",
      "published": "2025-12-19T05:00:00+00:00",
      "summary": "arXiv:2512.15742v1 Announce Type: new Abstract: Kolmogorov-Arnold Networks (KANs) face a fundamental memory wall: their learned basis functions create parameter counts that impose extreme bandwidth demands, hindering deployment in memory-constrained environments. We show that Vision KANs exhibit a holographic topology, where information is distributed across the interference of splines rather than..."
    },
    {
      "source_id": "arxiv_cs_lg",
      "source_name": "arXiv cs.LG (Machine Learning)",
      "category": "arxiv",
      "title": "How Do Graph Signals Affect Recommendation: Unveiling the Mystery of Low and High-Frequency Graph Signals",
      "link": "https://arxiv.org/abs/2512.15744",
      "published": "2025-12-19T05:00:00+00:00",
      "summary": "arXiv:2512.15744v1 Announce Type: new Abstract: Spectral graph neural networks (GNNs) are highly effective in modeling graph signals, with their success in recommendation often attributed to low-pass filtering. However, recent studies highlight the importance of high-frequency signals. The role of low-frequency and high-frequency graph signals in recommendation remains unclear. This paper aims to ..."
    },
    {
      "source_id": "arxiv_cs_lg",
      "source_name": "arXiv cs.LG (Machine Learning)",
      "category": "arxiv",
      "title": "LLaDA2.0: Scaling Up Diffusion Language Models to 100B",
      "link": "https://arxiv.org/abs/2512.15745",
      "published": "2025-12-19T05:00:00+00:00",
      "summary": "arXiv:2512.15745v1 Announce Type: new Abstract: This paper presents LLaDA2.0 -- a tuple of discrete diffusion large language models (dLLM) scaling up to 100B total parameters through systematic conversion from auto-regressive (AR) models -- establishing a new paradigm for frontier-scale deployment. Instead of costly training from scratch, LLaDA2.0 upholds knowledge inheritance, progressive adaptio..."
    },
    {
      "source_id": "arxiv_cs_cl",
      "source_name": "arXiv cs.CL (Computation and Language)",
      "category": "arxiv",
      "title": "TabReX : Tabular Referenceless eXplainable Evaluation",
      "link": "https://arxiv.org/abs/2512.15907",
      "published": "2025-12-19T05:00:00+00:00",
      "summary": "arXiv:2512.15907v1 Announce Type: new Abstract: Evaluating the quality of tables generated by large language models (LLMs) remains an open challenge: existing metrics either flatten tables into text, ignoring structure, or rely on fixed references that limit generalization. We present TabReX, a reference-less, property-driven framework for evaluating tabular generation via graph-based reasoning. T..."
    },
    {
      "source_id": "arxiv_cs_cl",
      "source_name": "arXiv cs.CL (Computation and Language)",
      "category": "arxiv",
      "title": "Social Story Frames: Contextual Reasoning about Narrative Intent and Reception",
      "link": "https://arxiv.org/abs/2512.15925",
      "published": "2025-12-19T05:00:00+00:00",
      "summary": "arXiv:2512.15925v1 Announce Type: new Abstract: Reading stories evokes rich interpretive, affective, and evaluative responses, such as inferences about narrative intent or judgments about characters. Yet, computational models of reader response are limited, preventing nuanced analyses. To address this gap, we introduce SocialStoryFrames, a formalism for distilling plausible inferences about reader..."
    },
    {
      "source_id": "arxiv_cs_cl",
      "source_name": "arXiv cs.CL (Computation and Language)",
      "category": "arxiv",
      "title": "BRAID: Bounded Reasoning for Autonomous Inference and Decisions",
      "link": "https://arxiv.org/abs/2512.15959",
      "published": "2025-12-19T05:00:00+00:00",
      "summary": "arXiv:2512.15959v1 Announce Type: new Abstract: Large Language Models (LLMs) exhibit nonlinear relationships between performance, cost, and token usage. This paper presents a quantitative study on structured prompting using BRAID (Bounded Reasoning for Au tonomous Inference and Decisions) across multiple GPT model tiers, eval uated on the AdvancedIF, GSM-Hard, and the SCALE MultiChallenge benchmar..."
    },
    {
      "source_id": "arxiv_cs_cl",
      "source_name": "arXiv cs.CL (Computation and Language)",
      "category": "arxiv",
      "title": "Examining the Utility of Self-disclosure Types for Modeling Annotators of Social Norms",
      "link": "https://arxiv.org/abs/2512.16034",
      "published": "2025-12-19T05:00:00+00:00",
      "summary": "arXiv:2512.16034v1 Announce Type: new Abstract: Recent work has explored the use of personal information in the form of persona sentences or self-disclosures to improve modeling of individual characteristics and prediction of annotator labels for subjective tasks. The volume of personal information has historically been restricted and thus little exploration has gone into understanding what kind o..."
    },
    {
      "source_id": "arxiv_cs_cl",
      "source_name": "arXiv cs.CL (Computation and Language)",
      "category": "arxiv",
      "title": "Are We on the Right Way to Assessing LLM-as-a-Judge?",
      "link": "https://arxiv.org/abs/2512.16041",
      "published": "2025-12-19T05:00:00+00:00",
      "summary": "arXiv:2512.16041v1 Announce Type: new Abstract: LLM-as-a-Judge has been widely adopted as an evaluation method and served as supervised rewards in model training. However, existing benchmarks for LLM-as-a-Judge are mainly relying on human-annotated ground truth, which introduces human bias that undermines the assessment of reliability and imposes scalability constraints. To overcome these limitati..."
    },
    {
      "source_id": "arxiv_cs_ai",
      "source_name": "arXiv cs.AI (Artificial Intelligence)",
      "category": "arxiv",
      "title": "Attention as Binding: A Vector-Symbolic Perspective on Transformer Reasoning",
      "link": "https://arxiv.org/abs/2512.14709",
      "published": "2025-12-19T05:00:00+00:00",
      "summary": "arXiv:2512.14709v1 Announce Type: new Abstract: Transformer-based language models display impressive reasoning-like behavior, yet remain brittle on tasks that require stable symbolic manipulation. This paper develops a unified perspective on these phenomena by interpreting self-attention and residual streams as implementing an approximate Vector Symbolic Architecture (VSA). In this view, queries a..."
    },
    {
      "source_id": "arxiv_cs_ai",
      "source_name": "arXiv cs.AI (Artificial Intelligence)",
      "category": "arxiv",
      "title": "GR-Agent: Adaptive Graph Reasoning Agent under Incomplete Knowledge",
      "link": "https://arxiv.org/abs/2512.14766",
      "published": "2025-12-19T05:00:00+00:00",
      "summary": "arXiv:2512.14766v1 Announce Type: new Abstract: Large language models (LLMs) achieve strong results on knowledge graph question answering (KGQA), but most benchmarks assume complete knowledge graphs (KGs) where direct supporting triples exist. This reduces evaluation to shallow retrieval and overlooks the reality of incomplete KGs, where many facts are missing and answers must be inferred from exi..."
    },
    {
      "source_id": "arxiv_cs_ai",
      "source_name": "arXiv cs.AI (Artificial Intelligence)",
      "category": "arxiv",
      "title": "IaC Generation with LLMs: An Error Taxonomy and A Study on Configuration Knowledge Injection",
      "link": "https://arxiv.org/abs/2512.14792",
      "published": "2025-12-19T05:00:00+00:00",
      "summary": "arXiv:2512.14792v1 Announce Type: new Abstract: Large Language Models (LLMs) currently exhibit low success rates in generating correct and intent-aligned Infrastructure as Code (IaC). This research investigated methods to improve LLM-based IaC generation, specifically for Terraform, by systematically injecting structured configuration knowledge. To facilitate this, an existing IaC-Eval benchmark w..."
    },
    {
      "source_id": "arxiv_cs_ai",
      "source_name": "arXiv cs.AI (Artificial Intelligence)",
      "category": "arxiv",
      "title": "AgroAskAI: A Multi-Agentic AI Framework for Supporting Smallholder Farmers' Enquiries Globally",
      "link": "https://arxiv.org/abs/2512.14910",
      "published": "2025-12-19T05:00:00+00:00",
      "summary": "arXiv:2512.14910v1 Announce Type: new Abstract: Agricultural regions in rural areas face damage from climate-related risks, including droughts, heavy rainfall, and shifting weather patterns. Prior research calls for adaptive risk-management solutions and decision-making strategies. To this end, artificial intelligence (AI), particularly agentic AI, offers a promising path forward. Agentic AI syste..."
    },
    {
      "source_id": "arxiv_cs_ai",
      "source_name": "arXiv cs.AI (Artificial Intelligence)",
      "category": "arxiv",
      "title": "Beyond Accuracy: A Geometric Stability Analysis of Large Language Models in Chess Evaluation",
      "link": "https://arxiv.org/abs/2512.15033",
      "published": "2025-12-19T05:00:00+00:00",
      "summary": "arXiv:2512.15033v1 Announce Type: new Abstract: The evaluation of Large Language Models (LLMs) in complex reasoning domains typically relies on performance alignment with ground-truth oracles. In the domain of chess, this standard manifests as accuracy benchmarks against strong engines like Stockfish. However, high scalar accuracy does not necessarily imply robust conceptual understanding. This pa..."
    }
  ]
}