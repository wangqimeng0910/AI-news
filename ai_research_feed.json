{
  "generated_at": "2025-12-18T02:47:55.042369+00:00",
  "count": 25,
  "items": [
    {
      "source_id": "openai_news",
      "source_name": "OpenAI News",
      "category": "company",
      "title": "Introducing OpenAI Academy for News Organizations",
      "link": "https://openai.com/index/openai-academy-for-news-organizations",
      "published": "2025-12-17T06:00:00+00:00",
      "summary": "OpenAI is launching the OpenAI Academy for News Organizations, a new learning hub built with the American Journalism Project and The Lenfest Institute to help newsrooms use AI effectively. The Academy offers training, practical use cases, and responsible-use guidance to support journalists, editors, and publishers as they adopt AI in their reporting and operations."
    },
    {
      "source_id": "openai_news",
      "source_name": "OpenAI News",
      "category": "company",
      "title": "Developers can now submit apps to ChatGPT",
      "link": "https://openai.com/index/developers-can-now-submit-apps-to-chatgpt",
      "published": "2025-12-17T00:00:00+00:00",
      "summary": "Developers can now submit apps for review and publication in ChatGPT, with approved apps appearing in a new in-product directory for easy discovery. Updated tools, guidelines, and the Apps SDK help developers build powerful chat-native experiences that bring real-world actions into ChatGPT."
    },
    {
      "source_id": "openai_news",
      "source_name": "OpenAI News",
      "category": "company",
      "title": "Evaluating AI’s ability to perform scientific research tasks",
      "link": "https://openai.com/index/frontierscience",
      "published": "2025-12-16T09:00:00+00:00",
      "summary": "OpenAI introduces FrontierScience, a benchmark testing AI reasoning in physics, chemistry, and biology to measure progress toward real scientific research."
    },
    {
      "source_id": "openai_news",
      "source_name": "OpenAI News",
      "category": "company",
      "title": "Measuring AI’s capability to accelerate biological research",
      "link": "https://openai.com/index/accelerating-biological-research-in-the-wet-lab",
      "published": "2025-12-16T08:00:00+00:00",
      "summary": "OpenAI introduces a real-world evaluation framework to measure how AI can accelerate biological research in the wet lab. Using GPT-5 to optimize a molecular cloning protocol, the work explores both the promise and risks of AI-assisted experimentation."
    },
    {
      "source_id": "openai_news",
      "source_name": "OpenAI News",
      "category": "company",
      "title": "The new ChatGPT Images is here",
      "link": "https://openai.com/index/new-chatgpt-images-is-here",
      "published": "2025-12-16T00:00:00+00:00",
      "summary": "The new ChatGPT Images is powered by our flagship image generation model, delivering more precise edits, consistent details, and image generation up to 4× faster. The upgraded model is rolling out to all ChatGPT users today and is also available in the API as GPT-Image-1.5."
    },
    {
      "source_id": "deepmind_news",
      "source_name": "Google DeepMind",
      "category": "company",
      "title": "Gemini 3 Flash: frontier intelligence built for speed",
      "link": "https://blog.google/products/gemini/gemini-3-flash/",
      "published": "2025-12-17T16:00:00+00:00",
      "summary": "Gemini 3 Flash text"
    },
    {
      "source_id": "deepmind_news",
      "source_name": "Google DeepMind",
      "category": "company",
      "title": "The latest AI news we announced in November",
      "link": "https://blog.google/technology/ai/google-ai-updates-november-2025/",
      "published": "2025-12-05T19:45:00+00:00",
      "summary": "mp4 showing a carousel of images with text like \"Gemini 3\" \"Nano Banana Pro\" and \"Help me plan a trip\""
    },
    {
      "source_id": "deepmind_news",
      "source_name": "Google DeepMind",
      "category": "company",
      "title": "Watch ‘The Thinking Game,’ a documentary about Google DeepMind, for free on YouTube.",
      "link": "https://blog.google/technology/google-deepmind/the-thinking-game/",
      "published": "2025-11-25T16:00:00+00:00",
      "summary": "We’re bringing “The Thinking Game\" to the Google DeepMind YouTube channel."
    },
    {
      "source_id": "deepmind_news",
      "source_name": "Google DeepMind",
      "category": "company",
      "title": "How we’re bringing AI image verification to the Gemini app",
      "link": "https://blog.google/technology/ai/ai-image-verification-gemini-app/",
      "published": "2025-11-20T15:00:00+00:00",
      "summary": "Golden retriever catching frisbee over water. UI overlay shows Google AI watermark detected."
    },
    {
      "source_id": "deepmind_news",
      "source_name": "Google DeepMind",
      "category": "company",
      "title": "Google DeepMind is opening a new AI research lab in Singapore to advance AI in Asia Pacific.",
      "link": "https://blog.google/around-the-globe/google-asia/google-deepmind-is-opening-a-new-ai-research-lab-in-singapore-to-advance-ai-in-asia-pacific/",
      "published": "2025-11-19T02:30:00+00:00",
      "summary": "Four individuals standing in front of a screen with the words “New Singapore AI research Lab” behind them"
    },
    {
      "source_id": "arxiv_cs_lg",
      "source_name": "arXiv cs.LG (Machine Learning)",
      "category": "arxiv",
      "title": "Physics-Guided Deep Learning for Heat Pump Stress Detection: A Comprehensive Analysis on When2Heat Dataset",
      "link": "https://arxiv.org/abs/2512.13696",
      "published": "2025-12-17T05:00:00+00:00",
      "summary": "arXiv:2512.13696v1 Announce Type: new Abstract: Heat pump systems are critical components in modern energy-efficient buildings, yet their operational stress detection remains challenging due to complex thermodynamic interactions and limited real-world data. This paper presents a novel Physics-Guided Deep Neural Network (PG-DNN) approach for heat pump stress classification using the When2Heat datas..."
    },
    {
      "source_id": "arxiv_cs_lg",
      "source_name": "arXiv cs.LG (Machine Learning)",
      "category": "arxiv",
      "title": "Scaling and Transferability of Annealing Strategies in Large Language Model Training",
      "link": "https://arxiv.org/abs/2512.13705",
      "published": "2025-12-17T05:00:00+00:00",
      "summary": "arXiv:2512.13705v1 Announce Type: new Abstract: Learning rate scheduling is crucial for training large language models, yet understanding the optimal annealing strategies across different model configurations remains challenging. In this work, we investigate the transferability of annealing dynamics in large language model training and refine a generalized predictive framework for optimizing annea..."
    },
    {
      "source_id": "arxiv_cs_lg",
      "source_name": "arXiv cs.LG (Machine Learning)",
      "category": "arxiv",
      "title": "Mitigating Catastrophic Forgetting in Mathematical Reasoning Finetuning through Mixed Training",
      "link": "https://arxiv.org/abs/2512.13706",
      "published": "2025-12-17T05:00:00+00:00",
      "summary": "arXiv:2512.13706v1 Announce Type: new Abstract: When finetuning large language models for specialized tasks such as mathematical reasoning, models exhibit catastrophic forgetting, losing previously learned capabilities. We investigate this by finetuning Flan-T5-Base (250M parameters) on the DeepMind Mathematics dataset and measuring forgetting on MultiNLI. Math-only training improves mathematical ..."
    },
    {
      "source_id": "arxiv_cs_lg",
      "source_name": "arXiv cs.LG (Machine Learning)",
      "category": "arxiv",
      "title": "Variational Physics-Informed Ansatz for Reconstructing Hidden Interaction Networks from Steady States",
      "link": "https://arxiv.org/abs/2512.13708",
      "published": "2025-12-17T05:00:00+00:00",
      "summary": "arXiv:2512.13708v1 Announce Type: new Abstract: The interaction structure of a complex dynamical system governs its collective behavior, yet existing reconstruction methods struggle with nonlinear, heterogeneous, and higher-order couplings, especially when only steady states are observable. We propose a Variational Physics-Informed Ansatz (VPIA) that infers general interaction operators directly f..."
    },
    {
      "source_id": "arxiv_cs_lg",
      "source_name": "arXiv cs.LG (Machine Learning)",
      "category": "arxiv",
      "title": "Predictive Modeling of Flood-Prone Areas Using SAR and Environmental Variables",
      "link": "https://arxiv.org/abs/2512.13710",
      "published": "2025-12-17T05:00:00+00:00",
      "summary": "arXiv:2512.13710v1 Announce Type: new Abstract: Flooding is one of the most destructive natural hazards worldwide, posing serious risks to ecosystems, infrastructure, and human livelihoods. This study combines Synthetic Aperture Radar (SAR) imagery with environmental and hydrological data to model flood susceptibility in the River Nyando watershed, western Kenya. Sentinel-1 dual-polarization SAR d..."
    },
    {
      "source_id": "arxiv_cs_cl",
      "source_name": "arXiv cs.CL (Computation and Language)",
      "category": "arxiv",
      "title": "FiNERweb: Datasets and Artifacts for Scalable Multilingual Named Entity Recognition",
      "link": "https://arxiv.org/abs/2512.13884",
      "published": "2025-12-17T05:00:00+00:00",
      "summary": "arXiv:2512.13884v1 Announce Type: new Abstract: Recent multilingual named entity recognition (NER) work has shown that large language models (LLMs) can provide effective synthetic supervision, yet such datasets have mostly appeared as by-products of broader experiments rather than as systematic, reusable resources. We introduce FiNERweb, a dataset-creation pipeline that scales the teacher-student ..."
    },
    {
      "source_id": "arxiv_cs_cl",
      "source_name": "arXiv cs.CL (Computation and Language)",
      "category": "arxiv",
      "title": "Olmo 3",
      "link": "https://arxiv.org/abs/2512.13961",
      "published": "2025-12-17T05:00:00+00:00",
      "summary": "arXiv:2512.13961v1 Announce Type: new Abstract: We introduce Olmo 3, a family of state-of-the-art, fully-open language models at the 7B and 32B parameter scales. Olmo 3 model construction targets long-context reasoning, function calling, coding, instruction following, general chat, and knowledge recall. This release includes the entire model flow, i.e., the full lifecycle of the family of models, ..."
    },
    {
      "source_id": "arxiv_cs_cl",
      "source_name": "arXiv cs.CL (Computation and Language)",
      "category": "arxiv",
      "title": "Structure-Aware Decoding Mechanisms for Complex Entity Extraction with Large-Scale Language Models",
      "link": "https://arxiv.org/abs/2512.13980",
      "published": "2025-12-17T05:00:00+00:00",
      "summary": "arXiv:2512.13980v1 Announce Type: new Abstract: This paper proposes a structure-aware decoding method based on large language models to address the difficulty of traditional approaches in maintaining both semantic integrity and structural consistency in nested and overlapping entity extraction tasks. The method introduces a candidate span generation mechanism and structured attention modeling to a..."
    },
    {
      "source_id": "arxiv_cs_cl",
      "source_name": "arXiv cs.CL (Computation and Language)",
      "category": "arxiv",
      "title": "What Affects the Effective Depth of Large Language Models?",
      "link": "https://arxiv.org/abs/2512.14064",
      "published": "2025-12-17T05:00:00+00:00",
      "summary": "arXiv:2512.14064v1 Announce Type: new Abstract: The scaling of large language models (LLMs) emphasizes increasing depth, yet performance gains diminish with added layers. Prior work introduces the concept of \"effective depth\", arguing that deeper models fail to fully utilize their layers for meaningful computation. Building on this, we systematically study how effective depth varies with model sca..."
    },
    {
      "source_id": "arxiv_cs_cl",
      "source_name": "arXiv cs.CL (Computation and Language)",
      "category": "arxiv",
      "title": "Efficient-DLM: From Autoregressive to Diffusion Language Models, and Beyond in Speed",
      "link": "https://arxiv.org/abs/2512.14067",
      "published": "2025-12-17T05:00:00+00:00",
      "summary": "arXiv:2512.14067v1 Announce Type: new Abstract: Diffusion language models (dLMs) have emerged as a promising paradigm that enables parallel, non-autoregressive generation, but their learning efficiency lags behind that of autoregressive (AR) language models when trained from scratch. To this end, we study AR-to-dLM conversion to transform pretrained AR models into efficient dLMs that excel in spee..."
    },
    {
      "source_id": "arxiv_cs_ai",
      "source_name": "arXiv cs.AI (Artificial Intelligence)",
      "category": "arxiv",
      "title": "Leveraging LLMs for Structured Data Extraction from Unstructured Patient Records",
      "link": "https://arxiv.org/abs/2512.13700",
      "published": "2025-12-17T05:00:00+00:00",
      "summary": "arXiv:2512.13700v1 Announce Type: new Abstract: Manual chart review remains an extremely time-consuming and resource-intensive component of clinical research, requiring experts to extract often complex information from unstructured electronic health record (EHR) narratives. We present a secure, modular framework for automated structured feature extraction from clinical notes leveraging locally dep..."
    },
    {
      "source_id": "arxiv_cs_ai",
      "source_name": "arXiv cs.AI (Artificial Intelligence)",
      "category": "arxiv",
      "title": "Blind Radio Mapping via Spatially Regularized Bayesian Trajectory Inference",
      "link": "https://arxiv.org/abs/2512.13701",
      "published": "2025-12-17T05:00:00+00:00",
      "summary": "arXiv:2512.13701v1 Announce Type: new Abstract: Radio maps enable intelligent wireless applications by capturing the spatial distribution of channel characteristics. However, conventional construction methods demand extensive location-labeled data, which are costly and impractical in many real-world scenarios. This paper presents a blind radio map construction framework that infers user trajectori..."
    },
    {
      "source_id": "arxiv_cs_ai",
      "source_name": "arXiv cs.AI (Artificial Intelligence)",
      "category": "arxiv",
      "title": "Adjudicator: Correcting Noisy Labels with a KG-Informed Council of LLM Agents",
      "link": "https://arxiv.org/abs/2512.13704",
      "published": "2025-12-17T05:00:00+00:00",
      "summary": "arXiv:2512.13704v1 Announce Type: new Abstract: The performance of production machine learning systems is fundamentally limited by the quality of their training data. In high-stakes industrial applications, noisy labels can degrade performance and erode user trust. This paper presents Adjudicator, a system that addresses the critical data mining challenge of automatically identifying and correctin..."
    },
    {
      "source_id": "arxiv_cs_ai",
      "source_name": "arXiv cs.AI (Artificial Intelligence)",
      "category": "arxiv",
      "title": "LoopBench: Discovering Emergent Symmetry Breaking Strategies with LLM Swarms",
      "link": "https://arxiv.org/abs/2512.13713",
      "published": "2025-12-17T05:00:00+00:00",
      "summary": "arXiv:2512.13713v1 Announce Type: new Abstract: Large Language Models (LLMs) are increasingly being utilized as autonomous agents, yet their ability to coordinate in distributed systems remains poorly understood. We introduce \\textbf{LoopBench}, a benchmark to evaluate LLM reasoning in distributed symmetry breaking and meta-cognitive thinking. The benchmark focuses on coloring odd cycle graphs ($C..."
    },
    {
      "source_id": "arxiv_cs_ai",
      "source_name": "arXiv cs.AI (Artificial Intelligence)",
      "category": "arxiv",
      "title": "AI-Powered Annotation Pipelines for Stabilizing Large Language Models: A Human-AI Synergy Approach",
      "link": "https://arxiv.org/abs/2512.13714",
      "published": "2025-12-17T05:00:00+00:00",
      "summary": "arXiv:2512.13714v1 Announce Type: new Abstract: LLM implementations are failing in highly regulated industries owing to instability issues, inconsistent reasoning, hallucinations and performance variability, especially in workflows. These reliability issues restrict safe use of LLM in areas that need the precision of facts and consistent behavior (Aiyappa et al., 2023). The current methods of stab..."
    }
  ]
}