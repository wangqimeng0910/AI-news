{
  "generated_at": "2025-12-26T02:51:32.533564+00:00",
  "count": 25,
  "items": [
    {
      "source_id": "openai_news",
      "source_name": "OpenAI News",
      "category": "company",
      "title": "One in a million: celebrating the customers shaping AI’s future",
      "link": "https://openai.com/index/one-in-a-million-customers",
      "published": "2025-12-22T00:00:00+00:00",
      "summary": "More than one million customers around the world now use OpenAI to empower their teams and unlock new opportunities. This post highlights how companies like PayPal, Virgin Atlantic, BBVA, Cisco, Moderna, and Canva are transforming the way work gets done with AI."
    },
    {
      "source_id": "openai_news",
      "source_name": "OpenAI News",
      "category": "company",
      "title": "Continuously hardening ChatGPT Atlas against prompt injection",
      "link": "https://openai.com/index/hardening-atlas-against-prompt-injection",
      "published": "2025-12-22T00:00:00+00:00",
      "summary": "OpenAI is strengthening ChatGPT Atlas against prompt injection attacks using automated red teaming trained with reinforcement learning. This proactive discover-and-patch loop helps identify novel exploits early and harden the browser agent’s defenses as AI becomes more agentic."
    },
    {
      "source_id": "openai_news",
      "source_name": "OpenAI News",
      "category": "company",
      "title": "Evaluating chain-of-thought monitorability",
      "link": "https://openai.com/index/evaluating-chain-of-thought-monitorability",
      "published": "2025-12-18T12:00:00+00:00",
      "summary": "OpenAI introduces a new framework and evaluation suite for chain-of-thought monitorability, covering 13 evaluations across 24 environments. Our findings show that monitoring a model’s internal reasoning is far more effective than monitoring outputs alone, offering a promising path toward scalable control as AI systems grow more capable."
    },
    {
      "source_id": "openai_news",
      "source_name": "OpenAI News",
      "category": "company",
      "title": "Deepening our collaboration with the U.S. Department of Energy",
      "link": "https://openai.com/index/us-department-of-energy-collaboration",
      "published": "2025-12-18T11:00:00+00:00",
      "summary": "OpenAI and the U.S. Department of Energy have signed a memorandum of understanding to deepen collaboration on AI and advanced computing in support of scientific discovery. The agreement builds on ongoing work with national laboratories and helps establish a framework for applying AI to high-impact research across the DOE ecosystem."
    },
    {
      "source_id": "openai_news",
      "source_name": "OpenAI News",
      "category": "company",
      "title": "AI literacy resources for teens and parents",
      "link": "https://openai.com/index/ai-literacy-resources-for-teens-and-parents",
      "published": "2025-12-18T11:00:00+00:00",
      "summary": "OpenAI shares new AI literacy resources to help teens and parents use ChatGPT thoughtfully, safely, and with confidence. The guides include expert-vetted tips for responsible use, critical thinking, healthy boundaries, and supporting teens through emotional or sensitive topics."
    },
    {
      "source_id": "deepmind_news",
      "source_name": "Google DeepMind",
      "category": "company",
      "title": "Google's year in review: 8 areas with research breakthroughs in 2025",
      "link": "https://blog.google/technology/ai/2025-research-breakthroughs/",
      "published": "2025-12-23T17:00:00+00:00",
      "summary": "The image depicts a visual collage or mosaic of multiple different images, with one image in the center that is black and displays the text \"Gemini 3\"."
    },
    {
      "source_id": "deepmind_news",
      "source_name": "Google DeepMind",
      "category": "company",
      "title": "Watch a podcast discussion about Gemini 3 and the future of Search.",
      "link": "https://blog.google/technology/ai/release-notes-podcast-search/",
      "published": "2025-12-18T00:00:00+00:00",
      "summary": "Learn how Gemini 3 powers Google Search with Generative UI, Nano Banana, and interactive graphics."
    },
    {
      "source_id": "deepmind_news",
      "source_name": "Google DeepMind",
      "category": "company",
      "title": "Gemini 3 Flash: frontier intelligence built for speed",
      "link": "https://blog.google/products/gemini/gemini-3-flash/",
      "published": "2025-12-17T16:00:00+00:00",
      "summary": "Gemini 3 Flash text"
    },
    {
      "source_id": "deepmind_news",
      "source_name": "Google DeepMind",
      "category": "company",
      "title": "The latest AI news we announced in November",
      "link": "https://blog.google/technology/ai/google-ai-updates-november-2025/",
      "published": "2025-12-05T19:45:00+00:00",
      "summary": "mp4 showing a carousel of images with text like \"Gemini 3\" \"Nano Banana Pro\" and \"Help me plan a trip\""
    },
    {
      "source_id": "deepmind_news",
      "source_name": "Google DeepMind",
      "category": "company",
      "title": "Watch ‘The Thinking Game,’ a documentary about Google DeepMind, for free on YouTube.",
      "link": "https://blog.google/technology/google-deepmind/the-thinking-game/",
      "published": "2025-11-25T16:00:00+00:00",
      "summary": "We’re bringing “The Thinking Game\" to the Google DeepMind YouTube channel."
    },
    {
      "source_id": "arxiv_cs_lg",
      "source_name": "arXiv cs.LG (Machine Learning)",
      "category": "arxiv",
      "title": "Parameter-Efficient Neural CDEs via Implicit Function Jacobians",
      "link": "https://arxiv.org/abs/2512.20625",
      "published": "2025-12-25T05:00:00+00:00",
      "summary": "arXiv:2512.20625v1 Announce Type: new Abstract: Neural Controlled Differential Equations (Neural CDEs, NCDEs) are a unique branch of methods, specifically tailored for analysing temporal sequences. However, they come with drawbacks, the main one being the number of parameters, required for the method's operation. In this paper, we propose an alternative, parameter-efficient look at Neural CDEs. It..."
    },
    {
      "source_id": "arxiv_cs_lg",
      "source_name": "arXiv cs.LG (Machine Learning)",
      "category": "arxiv",
      "title": "Learning Evolving Latent Strategies for Multi-Agent Language Systems without Model Fine-Tuning",
      "link": "https://arxiv.org/abs/2512.20629",
      "published": "2025-12-25T05:00:00+00:00",
      "summary": "arXiv:2512.20629v1 Announce Type: new Abstract: This study proposes a multi-agent language framework that enables continual strategy evolution without fine-tuning the language model's parameters. The core idea is to liberate the latent vectors of abstract concepts from traditional static semantic representations, allowing them to be continuously updated through environmental interaction and reinfo..."
    },
    {
      "source_id": "arxiv_cs_lg",
      "source_name": "arXiv cs.LG (Machine Learning)",
      "category": "arxiv",
      "title": "Zero-Training Temporal Drift Detection for Transformer Sentiment Models: A Comprehensive Analysis on Authentic Social Media Streams",
      "link": "https://arxiv.org/abs/2512.20631",
      "published": "2025-12-25T05:00:00+00:00",
      "summary": "arXiv:2512.20631v1 Announce Type: new Abstract: We present a comprehensive zero-training temporal drift analysis of transformer-based sentiment models validated on authentic social media data from major real-world events. Through systematic evaluation across three transformer architectures and rigorous statistical validation on 12,279 authentic social media posts, we demonstrate significant model ..."
    },
    {
      "source_id": "arxiv_cs_lg",
      "source_name": "arXiv cs.LG (Machine Learning)",
      "category": "arxiv",
      "title": "Enhancing Lung Cancer Treatment Outcome Prediction through Semantic Feature Engineering Using Large Language Models",
      "link": "https://arxiv.org/abs/2512.20633",
      "published": "2025-12-25T05:00:00+00:00",
      "summary": "arXiv:2512.20633v1 Announce Type: new Abstract: Accurate prediction of treatment outcomes in lung cancer remains challenging due to the sparsity, heterogeneity, and contextual overload of real-world electronic health data. Traditional models often fail to capture semantic information across multimodal streams, while large-scale fine-tuning approaches are impractical in clinical workflows. We intro..."
    },
    {
      "source_id": "arxiv_cs_lg",
      "source_name": "arXiv cs.LG (Machine Learning)",
      "category": "arxiv",
      "title": "Real Time Detection and Quantitative Analysis of Spurious Forgetting in Continual Learning",
      "link": "https://arxiv.org/abs/2512.20634",
      "published": "2025-12-25T05:00:00+00:00",
      "summary": "arXiv:2512.20634v1 Announce Type: new Abstract: Catastrophic forgetting remains a fundamental challenge in continual learning for large language models. Recent work revealed that performance degradation may stem from spurious forgetting caused by task alignment disruption rather than true knowledge loss. However, this work only qualitatively describes alignment, relies on post-hoc analysis, and la..."
    },
    {
      "source_id": "arxiv_cs_cl",
      "source_name": "arXiv cs.CL (Computation and Language)",
      "category": "arxiv",
      "title": "Uncovering Competency Gaps in Large Language Models and Their Benchmarks",
      "link": "https://arxiv.org/abs/2512.20638",
      "published": "2025-12-25T05:00:00+00:00",
      "summary": "arXiv:2512.20638v1 Announce Type: new Abstract: The evaluation of large language models (LLMs) relies heavily on standardized benchmarks. These benchmarks provide useful aggregated metrics for a given capability, but those aggregated metrics can obscure (i) particular sub-areas where the LLMs are weak (\"model gaps\") and (ii) imbalanced coverage in the benchmarks themselves (\"benchmark gaps\"). We p..."
    },
    {
      "source_id": "arxiv_cs_cl",
      "source_name": "arXiv cs.CL (Computation and Language)",
      "category": "arxiv",
      "title": "SA-DiffuSeq: Addressing Computational and Scalability Challenges in Long-Document Generation with Sparse Attention",
      "link": "https://arxiv.org/abs/2512.20724",
      "published": "2025-12-25T05:00:00+00:00",
      "summary": "arXiv:2512.20724v1 Announce Type: new Abstract: Diffusion based approaches to long form text generation suffer from prohibitive computational cost and memory overhead as sequence length increases. We introduce SA-DiffuSeq, a diffusion framework that integrates sparse attention to fundamentally improve scalability for long document modeling. By selectively allocating attention within the diffusion ..."
    },
    {
      "source_id": "arxiv_cs_cl",
      "source_name": "arXiv cs.CL (Computation and Language)",
      "category": "arxiv",
      "title": "TokSuite: Measuring the Impact of Tokenizer Choice on Language Model Behavior",
      "link": "https://arxiv.org/abs/2512.20757",
      "published": "2025-12-25T05:00:00+00:00",
      "summary": "arXiv:2512.20757v1 Announce Type: new Abstract: Tokenizers provide the fundamental basis through which text is represented and processed by language models (LMs). Despite the importance of tokenization, its role in LM performance and behavior is poorly understood due to the challenge of measuring the impact of tokenization in isolation. To address this need, we present TokSuite, a collection of mo..."
    },
    {
      "source_id": "arxiv_cs_cl",
      "source_name": "arXiv cs.CL (Computation and Language)",
      "category": "arxiv",
      "title": "Adversarial Training for Failure-Sensitive User Simulation in Mental Health Dialogue Optimization",
      "link": "https://arxiv.org/abs/2512.20773",
      "published": "2025-12-25T05:00:00+00:00",
      "summary": "arXiv:2512.20773v1 Announce Type: new Abstract: Realistic user simulation is crucial for training and evaluating task-oriented dialogue (TOD) systems, yet creating simulators that accurately replicate human behavior remains challenging. A key property of effective simulators is their ability to expose failure modes of the systems they evaluate. We present an adversarial training framework that ite..."
    },
    {
      "source_id": "arxiv_cs_cl",
      "source_name": "arXiv cs.CL (Computation and Language)",
      "category": "arxiv",
      "title": "Large Language Models Approach Expert Pedagogical Quality in Math Tutoring but Differ in Instructional and Linguistic Profiles",
      "link": "https://arxiv.org/abs/2512.20780",
      "published": "2025-12-25T05:00:00+00:00",
      "summary": "arXiv:2512.20780v1 Announce Type: new Abstract: Recent work has explored the use of large language models for generating tutoring responses in mathematics, yet it remains unclear how closely their instructional behavior aligns with expert human practice. We examine this question using a controlled, turn-level comparison in which expert human tutors, novice human tutors, and multiple large language..."
    },
    {
      "source_id": "arxiv_cs_ai",
      "source_name": "arXiv cs.AI (Artificial Intelligence)",
      "category": "arxiv",
      "title": "PhysMaster: Building an Autonomous AI Physicist for Theoretical and Computational Physics Research",
      "link": "https://arxiv.org/abs/2512.19799",
      "published": "2025-12-25T05:00:00+00:00",
      "summary": "arXiv:2512.19799v1 Announce Type: new Abstract: Advances in LLMs have produced agents with knowledge and operational capabilities comparable to human scientists, suggesting potential to assist, accelerate, and automate research. However, existing studies mainly evaluate such systems on well-defined benchmarks or general tasks like literature retrieval, limiting their end-to-end problem-solving abi..."
    },
    {
      "source_id": "arxiv_cs_ai",
      "source_name": "arXiv cs.AI (Artificial Intelligence)",
      "category": "arxiv",
      "title": "A Branch-and-Price Algorithm for Fast and Equitable Last-Mile Relief Aid Distribution",
      "link": "https://arxiv.org/abs/2512.19882",
      "published": "2025-12-25T05:00:00+00:00",
      "summary": "arXiv:2512.19882v1 Announce Type: new Abstract: The distribution of relief supplies to shelters is a critical aspect of post-disaster humanitarian logistics. In major disasters, prepositioned supplies often fall short of meeting all demands. We address the problem of planning vehicle routes from a distribution center to shelters while allocating limited relief supplies. To balance efficiency and e..."
    },
    {
      "source_id": "arxiv_cs_ai",
      "source_name": "arXiv cs.AI (Artificial Intelligence)",
      "category": "arxiv",
      "title": "Interpolative Decoding: Exploring the Spectrum of Personality Traits in LLMs",
      "link": "https://arxiv.org/abs/2512.19937",
      "published": "2025-12-25T05:00:00+00:00",
      "summary": "arXiv:2512.19937v1 Announce Type: new Abstract: Recent research has explored using very large language models (LLMs) as proxies for humans in tasks such as simulation, surveys, and studies. While LLMs do not possess a human psychology, they often can emulate human behaviors with sufficiently high fidelity to drive simulations to test human behavioral hypotheses, exhibiting more nuance and range th..."
    },
    {
      "source_id": "arxiv_cs_ai",
      "source_name": "arXiv cs.AI (Artificial Intelligence)",
      "category": "arxiv",
      "title": "Zero-Shot Segmentation through Prototype-Guidance for Multi-Label Plant Species Identification",
      "link": "https://arxiv.org/abs/2512.19957",
      "published": "2025-12-25T05:00:00+00:00",
      "summary": "arXiv:2512.19957v1 Announce Type: new Abstract: This paper presents an approach developed to address the PlantClef 2025 challenge, which consists of a fine-grained multi-label species identification, over high-resolution images. Our solution focused on employing class prototypes obtained from the training dataset as a proxy guidance for training a segmentation Vision Transformer (ViT) on the test ..."
    },
    {
      "source_id": "arxiv_cs_ai",
      "source_name": "arXiv cs.AI (Artificial Intelligence)",
      "category": "arxiv",
      "title": "FGDCC: Fine-Grained Deep Cluster Categorization -- A Framework for Intra-Class Variability Problems in Plant Classification",
      "link": "https://arxiv.org/abs/2512.19960",
      "published": "2025-12-25T05:00:00+00:00",
      "summary": "arXiv:2512.19960v1 Announce Type: new Abstract: Intra-class variability is given according to the significance in the degree of dissimilarity between images within a class. In that sense, depending on its intensity, intra-class variability can hinder the learning process for DL models, specially when such classes are also underrepresented, which is a very common scenario in Fine-Grained Visual Cat..."
    }
  ]
}